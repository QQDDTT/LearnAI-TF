# 深度学习训练框架 - 完整项目结构

## 📁 项目目录树

```
LearnAI/
├── main.py                          # ✅ 主入口（配置驱动）
├── config/
│   └── config_example.yaml         # ✅ 示例配置文件
├── common/
│   ├── __init__.py
│   ├── common.py                   # ✅ 日志、反射、配置加载
│   └── utils.py                    # ✅ 纯工具函数
└── modules/                        # ✅ 核心业务模块
    ├── __init__.py                 # ✅ 模块导出
    ├── data_manager.py            # ✅ 数据管理（含增强）
    ├── models.py                  # ✅ 模型构建
    ├── optimizers.py              # ✅ 优化器管理
    ├── losses.py                  # ✅ 损失函数（含自定义）
    ├── training_pipeline.py       # ✅ 训练流程控制
    ├── evaluation.py              # ✅ 评估逻辑
    ├── reward_functions.py        # ✅ 强化学习奖励
    ├── export.py                  # ✅ 模型导出
    └── deployment.py              # ✅ 模型部署
```

## 🎯 架构设计

### 调用层次
```
配置文件 (YAML)
    ↓ main.py 读取配置
modules/* (核心业务逻辑)
    ↓ 内部调用
common/utils.py (工具函数)
    ↓ 基础支持
common/common.py (基础设施)
```

### 模块职责

| 模块 | 职责 | 主要函数 |
|------|------|---------|
| **main.py** | 主控制器 | `main()` - 读取配置、调度模块 |
| **data_manager.py** | 数据管理 | `initialize()` - 加载数据<br>`load_supervised_data()` - 监督学习数据<br>`load_rl_data()` - 强化学习数据<br>`apply_contrastive_augmentation()` - 对比增强 |
| **models.py** | 模型构建 | `build_all_models()` - 构建所有模型<br>`build_sequential_model()` - Sequential模型<br>`load_pretrained_model()` - 预训练模型 |
| **optimizers.py** | 优化器 | `build_all_optimizers()` - 构建优化器<br>`LearningRateScheduler` - 学习率调度 |
| **losses.py** | 损失函数 | `build_all_losses()` - 构建损失函数<br>`ContrastiveLoss` - 对比损失<br>`MultiTaskLoss` - 多任务损失<br>`aggregate_multi_task_losses()` - 多任务聚合 |
| **training_pipeline.py** | 训练控制 | `run_training()` - 主训练入口<br>`run_epoch_batch_training()` - Epoch-Batch循环<br>`run_episode_step_training()` - Episode-Step循环<br>`execute_step_sequence()` - 执行步骤序列 |
| **evaluation.py** | 评估 | `run_evaluation()` - 主评估入口<br>`evaluate_supervised()` - 监督学习评估<br>`evaluate_reinforcement()` - 强化学习评估 |
| **reward_functions.py** | 奖励函数 | `compute_basic_reward()` - 基础奖励<br>`compute_game_reward()` - 游戏奖励<br>`apply_potential_based_shaping()` - 奖励塑形 |
| **export.py** | 模型导出 | `export_model()` - 主导出函数<br>`export_to_onnx()` - ONNX导出<br>`export_to_saved_model()` - SavedModel导出 |
| **deployment.py** | 模型部署 | `deploy_model()` - 主部署函数<br>`deploy_rest_api()` - REST API部署 |

### common/utils.py 工具函数

| 类别 | 函数 | 说明 |
|------|------|------|
| **网络客户端** | `NetworkClient` | 强化学习环境接口 |
| **数据加载** | `build_csv_dataset()` | CSV数据集<br>`build_numpy_dataset()` | NumPy数据集<br>`build_web_dataset()` | 网络数据集 |
| **推理优化** | `forward()` | 前向传播<br>`compute_gradients()` | 计算梯度<br>`apply_gradients()` | 应用梯度<br>`compute_metrics()` | 计算指标 |
| **强化学习** | `compute_reward()` | 奖励计算<br>`select_action()` | 动作选择<br>`compute_gae()` | GAE计算<br>`observe_state()` | 观察状态<br>`execute_action()` | 执行动作<br>`store_transition()` | 存储经验 |
| **聚类** | `kmeans_cluster()` | K-Means聚类 |

## 🔄 执行流程

### 1. 启动流程
```python
python main.py config/config_example.yaml
```

### 2. main.py 执行步骤
```
1. 加载配置文件 → load_yaml()
2. 初始化数据 → data_manager.initialize()
3. 构建模型 → models.build_all_models()
4. 构建优化器 → optimizers.build_all_optimizers()
5. 构建损失 → losses.build_all_losses()
6. 训练 → training_pipeline.run_training()
7. 评估 → evaluation.run_evaluation()
8. 导出 → export.export_model()
9. 部署 → deployment.deploy_model()
```

### 3. 训练循环示例（监督学习）
```
training_pipeline.run_epoch_batch_training()
  ↓
for epoch in epochs:
    for batch in dataloader:
        execute_step_sequence([
            fetch_batch,
            forward_pass,
            compute_loss,
            backward_pass,
            update_params
        ])
```

### 4. 强化学习循环示例
```
training_pipeline.run_episode_step_training()
  ↓
for episode in episodes:
    for step in steps:
        execute_step_sequence([
            observe_state,
            policy_inference,
            select_action,
            execute_action,
            compute_reward,
            store_experience
        ])
```

## 📝 配置文件映射

| 配置节点 | 处理模块 | 说明 |
|---------|---------|------|
| `data_manager` | `modules/data_manager.py` | 数据加载和增强 |
| `models` | `modules/models.py` | 模型构建 |
| `optimizers` | `modules/optimizers.py` | 优化器构建 |
| `losses` | `modules/losses.py` | 损失函数构建 |
| `training_pipeline` | `modules/training_pipeline.py` | 训练流程执行 |
| `evaluation` | `modules/evaluation.py` | 评估执行 |
| `reward_functions` | `modules/reward_functions.py` | 奖励函数（强化学习） |
| `export` | `modules/export.py` | 模型导出 |
| `deployment` | `modules/deployment.py` | 模型部署 |

## ✅ 关键设计原则

### 1. **配置驱动**
- 所有行为通过YAML配置文件定义
- main.py 不包含业务逻辑，只负责调度

### 2. **模块职责单一**
- 每个 modules/* 文件对应配置的一个顶级节点
- 模块之间通过 context 传递数据

### 3. **反射调用**
- 配置中使用 `reflection` 字段动态调用函数
- 优先级：`modules/*` > `common.utils` > `tensorflow`

### 4. **清晰的边界**
- **modules/** = 业务逻辑（数据增强、对比损失、多任务聚合等）
- **common/utils.py** = 纯工具函数（被modules调用）
- **common/common.py** = 基础设施（日志、反射、配置）

### 5. **易扩展**
- 新增训练方式：在 `training_pipeline.py` 添加新函数
- 新增损失函数：在 `losses.py` 添加新类
- 新增数据源：在 `data_manager.py` 添加新函数

## 🚀 使用示例

### 监督学习
```bash
python main.py config/supervised_config.yaml
```

### 强化学习
```bash
python main.py config/reinforcement_config.yaml
```

### 自监督学习
```bash
python main.py config/self_supervised_config.yaml
```

## 📦 依赖安装

```bash
pip install tensorflow pandas numpy pyyaml colorama requests flask tf2onnx
```

## 🎓 总结

这个框架实现了：
✅ 完全配置驱动，无需修改代码
✅ 模块职责清晰，易于维护和扩展
✅ 支持监督、强化、自监督等多种训练方式
✅ 数据增强集成在 data_manager 中
✅ 对比损失、多任务损失集成在 losses 中
✅ 聚类算法作为工具函数在 utils 中
✅ 所有业务逻辑都在 modules 中，没有"节外生枝"

## 📚 核心文件说明

### main.py
- 入口文件，负责：
  - 读取配置文件
  - 初始化各模块
  - 调度训练流程
  - 不包含任何业务逻辑

### modules/data_manager.py
- **职责**：数据加载和管理
- **包含**：
  - 监督学习数据加载
  - 强化学习环境客户端
  - 自监督学习数据（含增强）
  - 数据增强逻辑（RandomCrop、RandomFlip、ColorJitter）
  - 对比学习数据对生成

### modules/losses.py
- **职责**：损失函数定义和管理
- **包含**：
  - TensorFlow内置损失的构建
  - 自定义损失类：
    - `ContrastiveLoss` - 对比学习损失
    - `MultiTaskLoss` - 多任务学习损失
    - `FocalLoss` - 类别不平衡损失
    - `TripletLoss` - 度量学习损失
  - 损失聚合函数：
    - `aggregate_multi_task_losses()` - 多任务损失聚合
  - 强化学习损失：
    - `compute_policy_gradient_loss()` - 策略梯度
    - `compute_ppo_loss()` - PPO损失
    - `compute_value_loss()` - 价值函数损失

### modules/training_pipeline.py
- **职责**：训练循环的执行
- **包含**：
  - `run_epoch_batch_training()` - 监督学习循环
  - `run_episode_step_training()` - 强化学习循环
  - `run_iteration_training()` - 迭代训练（聚类）
  - `execute_step_sequence()` - 步骤序列执行器
  - `resolve_arguments()` - 参数引用解析

### common/utils.py
- **职责**：纯工具函数（被modules调用）
- **包含**：
  - `NetworkClient` - 网络客户端
  - 数据加载：`build_csv_dataset()`, `build_numpy_dataset()`, `build_web_dataset()`
  - 推理优化：`forward()`, `compute_gradients()`, `apply_gradients()`
  - 强化学习：`compute_reward()`, `select_action()`, `compute_gae()`
  - 聚类：`kmeans_cluster()`
  - **注意**：这里只有工具函数，不包含业务逻辑

## 🔧 扩展指南

### 添加新的训练方式
1. 在 `config_example.yaml` 中添加新的 `training_pipeline` 配置节
2. 在 `modules/training_pipeline.py` 中添加对应的训练函数
3. 更新 `run_training()` 函数以支持新的 `loop_type`

示例：
```python
# modules/training_pipeline.py

def run_custom_training(parameters, step_sequence, context):
    """自定义训练循环"""
    # 实现你的训练逻辑
    pass
```

### 添加新的损失函数
1. 在 `modules/losses.py` 中定义新的损失类
2. 在配置文件中引用

示例：
```python
# modules/losses.py

class CustomLoss(tf.keras.losses.Loss):
    """自定义损失函数"""
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def call(self, y_true, y_pred):
        # 实现损失计算
        return loss
```

```yaml
# config.yaml
losses:
  custom_loss:
    reflection: modules.losses:CustomLoss
    args:
      param1: value1
```

### 添加新的数据增强
1. 在 `modules/data_manager.py` 的 `apply_transforms()` 函数中添加新的增强类型
2. 在配置文件中使用

示例：
```python
# modules/data_manager.py

def apply_transforms(data, transforms):
    for transform_config in transforms:
        transform_type = transform_config.get("type")

        if transform_type == "CustomAugment":
            # 实现自定义增强
            data = custom_augment(data, transform_config["args"])

    return data
```

### 添加新的工具函数
1. 在 `common/utils.py` 中添加纯工具函数
2. 在 modules 中通过 `from common import utils` 调用

示例：
```python
# common/utils.py

def custom_preprocessing(data, method="standard"):
    """自定义预处理函数"""
    # 实现预处理逻辑
    return processed_data
```

## 🐛 常见问题

### Q1: 如何添加新的模型架构？
**A**: 在 `modules/models.py` 中添加构建函数，或在配置文件中使用 TensorFlow 层定义。

### Q2: 如何自定义step_sequence？
**A**: 在配置文件的 `training_pipeline.{mode}.step_sequence` 中定义步骤列表，每个步骤指定 `reflection` 和 `args`。

### Q3: 参数引用如何工作？
**A**: `training_pipeline.py` 中的 `resolve_arguments()` 函数会解析：
- `"last_result"` → 上一步的结果
- `"batch.x"` → 当前batch的x字段
- `"${variable}"` → 上下文变量
- `"config.path"` → 配置文件中的值
- `"step_name.field"` → 之前步骤的结果字段

### Q4: 如何调试step执行？
**A**: 在 `execute_step_sequence()` 中添加日志，查看每个步骤的输入和输出。

### Q5: 聚类算法放在哪里？
**A**: 作为工具函数放在 `common/utils.py` 中，由 `data_manager` 或其他模块调用。

## 📊 架构对比

### ❌ 错误设计（节外生枝）
```
LearnAI/
├── common/
│   ├── clustering.py      # ❌ 独立模块
│   ├── augmentation.py    # ❌ 独立模块
│   └── losses.py          # ❌ 独立模块
```

### ✅ 正确设计（职责清晰）
```
LearnAI/
├── modules/               # 业务逻辑
│   ├── data_manager.py   # 包含增强逻辑
│   ├── losses.py         # 包含对比损失、多任务
│   └── ...
├── common/
│   └── utils.py          # 纯工具函数（包含聚类）
```

## 🎯 设计哲学

1. **配置是王道**：所有行为通过配置文件定义
2. **模块对应配置节点**：一个模块文件对应配置文件的一个顶级节点
3. **工具函数下沉**：可复用的纯函数放在 `utils.py`
4. **业务逻辑在modules**：增强、损失聚合等业务逻辑在对应模块中
5. **避免循环依赖**：modules 调用 utils，utils 不调用 modules

## 🚀 快速开始

```bash
# 1. 克隆项目
git clone <repo>

# 2. 安装依赖
pip install -r requirements.txt

# 3. 运行监督学习示例
python main.py config/config_example.yaml

# 4. 查看日志
tail -f logs/LearnAI_Framework_20251014.log
```

## 📈 性能优化建议

1. **数据加载**：使用 `tf.data.Dataset.prefetch()`
2. **混合精度训练**：使用 `tf.keras.mixed_precision`
3. **分布式训练**：使用 `tf.distribute.Strategy`
4. **模型量化**：导出时使用 TFLite 量化

## 🔐 安全建议

1. **配置文件验证**：添加配置文件schema验证
2. **输入验证**：在API部署时验证输入数据
3. **权限控制**：部署服务时添加认证机制

## 📝 贡献指南

1. Fork 项目
2. 创建特性分支 (`git checkout -b feature/AmazingFeature`)
3. 提交更改 (`git commit -m 'Add some AmazingFeature'`)
4. 推送到分支 (`git push origin feature/AmazingFeature`)
5. 打开 Pull Request

## 📄 许可证

MIT License

---

**项目完成！所有模块已生成。** 🎉
