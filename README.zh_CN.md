# LearnAI æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶

<div align="center">

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.9%2B-green.svg)
![TensorFlow](https://img.shields.io/badge/tensorflow-2.16.1-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**é…ç½®é©±åŠ¨ Â· æ¨¡å—åŒ–è®¾è®¡ Â· å¤šæ¨¡å¼è®­ç»ƒ Â· ç”Ÿäº§å°±ç»ª**

[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) â€¢ [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§) â€¢ [æ–‡æ¡£](#æ–‡æ¡£) â€¢ [ç¤ºä¾‹](#ç¤ºä¾‹) â€¢ [è´¡çŒ®](#è´¡çŒ®)

</div>

---

## ğŸ“– ç›®å½•

- [ç®€ä»‹](#ç®€ä»‹)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å®‰è£…](#å®‰è£…)
- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)
- [é…ç½®æ–‡ä»¶](#é…ç½®æ–‡ä»¶)
- [æ”¯æŒçš„è®­ç»ƒæ¨¡å¼](#æ”¯æŒçš„è®­ç»ƒæ¨¡å¼)
- [æ¨¡å‹å¯¼å‡ºä¸éƒ¨ç½²](#æ¨¡å‹å¯¼å‡ºä¸éƒ¨ç½²)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [å¼€å‘æŒ‡å—](#å¼€å‘æŒ‡å—)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ›´æ–°æ—¥å¿—](#æ›´æ–°æ—¥å¿—)
- [è´¡çŒ®æŒ‡å—](#è´¡çŒ®æŒ‡å—)
- [è®¸å¯è¯](#è®¸å¯è¯)

---

## ç®€ä»‹

**LearnAI** æ˜¯ä¸€ä¸ªåŸºäº TensorFlow 2.x çš„ä¼ä¸šçº§æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œé‡‡ç”¨é…ç½®é©±åŠ¨æ¶æ„ï¼Œæ”¯æŒç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€è‡ªç›‘ç£å­¦ä¹ ç­‰å¤šç§è®­ç»ƒèŒƒå¼ã€‚æ¡†æ¶é€šè¿‡ YAML é…ç½®æ–‡ä»¶å®šä¹‰å…¨éƒ¨è®­ç»ƒæµç¨‹ï¼Œæ— éœ€ä¿®æ”¹ä»£ç å³å¯å®Œæˆå¤æ‚çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ã€‚

### ä¸ºä»€ä¹ˆé€‰æ‹© LearnAIï¼Ÿ

- âœ… **é›¶ä»£ç è®­ç»ƒ**ï¼šä»…é€šè¿‡ YAML é…ç½®å³å¯å®Œæˆæ¨¡å‹è®­ç»ƒ
- âœ… **å¤šæ¨¡å¼æ”¯æŒ**ï¼šæ”¯æŒ 7 ç§ä¸»æµè®­ç»ƒèŒƒå¼
- âœ… **ç”Ÿäº§å°±ç»ª**ï¼šå†…ç½®æ¨¡å‹å¯¼å‡ºã€éƒ¨ç½²å’Œç›‘æ§åŠŸèƒ½
- âœ… **é«˜åº¦çµæ´»**ï¼šåå°„æœºåˆ¶æ”¯æŒåŠ¨æ€åŠ è½½ä»»ä½• Python ç»„ä»¶
- âœ… **ä¼ä¸šçº§è´¨é‡**ï¼šå®Œæ•´çš„æµ‹è¯•è¦†ç›–ã€æ—¥å¿—ç³»ç»Ÿå’Œé”™è¯¯å¤„ç†

---

## æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ é…ç½®é©±åŠ¨æ¶æ„

```yaml
# ä¸€ä¸ªé…ç½®æ–‡ä»¶å®šä¹‰å®Œæ•´è®­ç»ƒæµç¨‹
global:
  name: "image_classifier"
  version: "v1.0.0"

training_mode:
  type: "supervised"

models:
  classifier:
    # ä½¿ç”¨åå°„æœºåˆ¶åŠ¨æ€åŠ è½½æ¨¡å‹
    reflection: "tensorflow.keras.Sequential"
    layers:
      - name: "conv1"
        reflection: "tensorflow.keras.layers.Conv2D"
        args: {filters: 32, kernel_size: [3,3]}
```

### ğŸš€ æ”¯æŒçš„åŠŸèƒ½

| åŠŸèƒ½ç±»åˆ« | æ”¯æŒå†…å®¹ |
|---------|---------|
| **è®­ç»ƒæ¨¡å¼** | ç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ ã€è‡ªç›‘ç£å­¦ä¹ ã€åŠç›‘ç£å­¦ä¹ ã€å¤šä»»åŠ¡å­¦ä¹ ã€è‡ªå®šä¹‰è®­ç»ƒ |
| **æ•°æ®æº** | CSVã€NumPyã€å›¾åƒç›®å½•ã€TFRecordã€ç½‘ç»œ APIã€è‡ªå®šä¹‰åŠ è½½å™¨ |
| **æ¨¡å‹æ¶æ„** | Keras Sequentialã€Functional APIã€Model Subclassingã€é¢„è®­ç»ƒæ¨¡å‹ã€è‡ªå®šä¹‰æ¨¡å‹ |
| **ä¼˜åŒ–å™¨** | Adamã€SGDã€RMSpropã€AdaGrad ç­‰æ‰€æœ‰ TensorFlow ä¼˜åŒ–å™¨ + å­¦ä¹ ç‡è°ƒåº¦ |
| **æŸå¤±å‡½æ•°** | TensorFlow å†…ç½®æŸå¤± + è‡ªå®šä¹‰æŸå¤±ï¼ˆå¯¹æ¯”æŸå¤±ã€Focal Lossã€å¤šä»»åŠ¡æŸå¤±ç­‰ï¼‰ |
| **å¯¼å‡ºæ ¼å¼** | SavedModelã€ONNXã€TensorFlow Liteã€H5ã€ä»…æƒé‡ |
| **éƒ¨ç½²æ–¹å¼** | REST APIã€gRPCã€TensorFlow Servingã€Dockerã€è‡ªå®šä¹‰éƒ¨ç½² |

### ğŸ› ï¸ åå°„æœºåˆ¶

é€šè¿‡ `reflection` å­—æ®µåŠ¨æ€è°ƒç”¨ä»»ä½• Python ç±»æˆ–å‡½æ•°ï¼š

```yaml
# è°ƒç”¨ TensorFlow ç»„ä»¶
reflection: "tensorflow.keras.optimizers.Adam"

# è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°
reflection: "modules.custom:my_training_function"

# è°ƒç”¨ç¬¬ä¸‰æ–¹åº“
reflection: "sklearn.preprocessing.StandardScaler"
```

### ğŸ“Š é«˜çº§è®­ç»ƒæµç¨‹æ§åˆ¶

æ”¯æŒ Bridge è¡¨è¾¾å¼è¿›è¡Œæ¡ä»¶æ§åˆ¶ï¼š

```yaml
step_sequence:
  - name: "validation"
    reflection: "modules.evaluation:validate"
    bridge: "@skip:validation?${epoch}%10!=0"  # æ¯10è½®éªŒè¯ä¸€æ¬¡

  - name: "early_stop"
    reflection: "common.utils:check_convergence"
    bridge: "@jump:save_model?${accuracy}>0.95"  # è¾¾åˆ°ç›®æ ‡åè·³è½¬
```

---

## ç³»ç»Ÿæ¶æ„

### è®¾è®¡ç†å¿µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    YAML é…ç½®æ–‡ä»¶                         â”‚
â”‚          (å”¯ä¸€çš„æ§åˆ¶ä¸­å¿ƒï¼Œå®šä¹‰æ‰€æœ‰è®­ç»ƒè¡Œä¸º)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“ (åŠ è½½å’ŒéªŒè¯)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    main.py                               â”‚
â”‚            (ä¸»å…¥å£ï¼Œåè°ƒå„æ¨¡å—æ‰§è¡Œ)                        â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚        â”‚          â”‚          â”‚          â”‚
     â†“        â†“          â†“          â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data    â”‚ Models  â”‚Optimizerâ”‚ Losses  â”‚Training â”‚
â”‚ Manager â”‚ Builder â”‚ Manager â”‚ Manager â”‚Pipeline â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“        â†“          â†“          â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          common/utils.py (å·¥å…·å‡½æ•°åº“)             â”‚
â”‚   â€¢ forward()  â€¢ compute_loss()  â€¢ backward()    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        TensorFlow 2.x / ç¬¬ä¸‰æ–¹åº“                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å—èŒè´£

| æ¨¡å— | æ–‡ä»¶ | èŒè´£ |
|------|------|------|
| **ä¸»æ§åˆ¶å™¨** | `main.py` | è¯»å–é…ç½®ã€åè°ƒæ¨¡å—æ‰§è¡Œã€ç®¡ç†ç”Ÿå‘½å‘¨æœŸ |
| **æ•°æ®ç®¡ç†** | `modules/data_manager.py` | æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€å¢å¼º |
| **æ¨¡å‹æ„å»º** | `modules/models.py` | æ¨¡å‹åˆ›å»ºã€å±‚å®šä¹‰ã€æ¶æ„ç®¡ç† |
| **ä¼˜åŒ–å™¨ç®¡ç†** | `modules/optimizers.py` | ä¼˜åŒ–å™¨é…ç½®ã€å­¦ä¹ ç‡è°ƒåº¦ |
| **æŸå¤±å‡½æ•°** | `modules/losses.py` | æŸå¤±è®¡ç®—ã€è‡ªå®šä¹‰æŸå¤± |
| **è®­ç»ƒæµç¨‹** | `modules/training_pipeline.py` | è®­ç»ƒå¾ªç¯ã€Bridge æ§åˆ¶ã€æ£€æŸ¥ç‚¹ |
| **æ¨¡å‹è¯„ä¼°** | `modules/evaluation.py` | æŒ‡æ ‡è®¡ç®—ã€æ¨¡å‹éªŒè¯ |
| **æ¨¡å‹å¯¼å‡º** | `modules/export.py` | å¤šæ ¼å¼å¯¼å‡ºã€æ¨¡å‹ä¼˜åŒ– |
| **æ¨¡å‹éƒ¨ç½²** | `modules/deployment.py` | æœåŠ¡éƒ¨ç½²ã€API åˆ›å»º |
| **å…¬å…±å·¥å…·** | `common/common.py` | æ—¥å¿—ã€åå°„ã€é…ç½®åŠ è½½ |
| **è®­ç»ƒä¸Šä¸‹æ–‡** | `common/train_context.py` | çŠ¶æ€ç®¡ç†ã€å˜é‡å­˜å‚¨ |

---

## å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚

- Python 3.9+
- TensorFlow 2.16.1
- 4GB+ RAMï¼ˆæ¨è 8GB+ï¼‰
- ï¼ˆå¯é€‰ï¼‰NVIDIA GPU with CUDA 12.3

### 30 ç§’å¿«é€Ÿä½“éªŒ

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/qqddtt/LearnAI.git
cd LearnAI

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. è¿è¡Œç¤ºä¾‹
python main.py config/config_example.yaml
```

### å®Œæ•´ç¤ºä¾‹ï¼šå›¾åƒåˆ†ç±»

```bash
# 1. å‡†å¤‡æ•°æ®
mkdir -p data/train data/val
# å°†å›¾åƒæ”¾å…¥å¯¹åº”ç›®å½•

# 2. åˆ›å»ºé…ç½®æ–‡ä»¶
cat > config/my_classifier.yaml << 'EOF'
global:
  name: "my_image_classifier"
  version: "v1.0.0"
  seed: 42

training_mode:
  type: "supervised"

models:
  classifier:
    reflection: "tensorflow.keras.Sequential"
    layers:
      - name: "conv1"
        reflection: "tensorflow.keras.layers.Conv2D"
        args: {filters: 32, kernel_size: [3,3], activation: "relu"}
      - name: "pool1"
        reflection: "tensorflow.keras.layers.MaxPooling2D"
        args: {pool_size: [2,2]}
      - name: "flatten"
        reflection: "tensorflow.keras.layers.Flatten"
      - name: "dense1"
        reflection: "tensorflow.keras.layers.Dense"
        args: {units: 128, activation: "relu"}
      - name: "output"
        reflection: "tensorflow.keras.layers.Dense"
        args: {units: 10, activation: "softmax"}

data_manager:
  supervised_source:
    train:
      reflection: "tensorflow.keras.preprocessing.image_dataset_from_directory"
      args:
        directory: "data/train"
        image_size: [128, 128]
        batch_size: 32
        label_mode: "categorical"

optimizers:
  main_optimizer:
    reflection: "tensorflow.keras.optimizers.Adam"
    args:
      learning_rate: 0.001

losses:
  classification_loss:
    reflection: "tensorflow.keras.losses.CategoricalCrossentropy"

training_pipeline:
  supervised:
    loop_config:
      type: "epoch_batch"
      parameters:
        epochs: 50
        batch_size: 32
    step_sequence:
      - name: "forward"
        reflection: "common.utils:forward"
        args: {model: "${classifier}", inputs: "${batch_data}"}
      - name: "loss"
        reflection: "common.utils:compute_loss"
        args: {loss_fn: "${classification_loss}", predictions: "${forward}", targets: "${batch_labels}"}
      - name: "backward"
        reflection: "common.utils:compute_gradients"
        args: {loss: "${loss}", model: "${classifier}"}
      - name: "update"
        reflection: "common.utils:apply_gradients"
        args: {optimizer: "${main_optimizer}", gradients: "${backward}", model: "${classifier}"}

evaluation:
  supervised_eval:
    reflection: "modules.evaluation:evaluate_supervised"
    args:
      model: "${classifier}"
      dataset: "${val_data}"
      metrics: ["accuracy", "precision", "recall"]

export:
  export_onnx:
    model: "${classifier}"
    format: "onnx"
    output_path: "outputs/onnx/classifier.onnx"
EOF

# 3. å¼€å§‹è®­ç»ƒ
python main.py config/my_classifier.yaml --export

# 4. æŸ¥çœ‹ç»“æœ
ls outputs/onnx/
```

---

## å®‰è£…

### å¿«é€Ÿå®‰è£…ï¼ˆæœ€å°ä¾èµ–ï¼‰

```bash
pip install tensorflow numpy pandas pyyaml colorama requests
```

### å®Œæ•´å®‰è£…ï¼ˆæ‰€æœ‰åŠŸèƒ½ï¼‰

```bash
pip install -r requirements.txt
```

### GPU æ”¯æŒ

```bash
# TensorFlow with CUDA
pip install tensorflow[and-cuda]==2.16.1

# éœ€è¦å®‰è£… CUDA 12.3 å’Œ cuDNN 8.9
```

### å›½å†…é•œåƒåŠ é€Ÿ

```bash
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt
```

### å¼€å‘ç¯å¢ƒ

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/qqddtt/LearnAI.git
cd LearnAI

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt  # åŒ…å«æµ‹è¯•å’Œä»£ç è´¨é‡å·¥å…·

# è¿è¡Œæµ‹è¯•
pytest test/
```

---

## ä½¿ç”¨æŒ‡å—

### å‘½ä»¤è¡Œå‚æ•°

```bash
python main.py <config_file> [options]

å¿…éœ€å‚æ•°:
  config_file          é…ç½®æ–‡ä»¶è·¯å¾„ (YAML)

å¯é€‰å‚æ•°:
  --export             è®­ç»ƒåå¯¼å‡ºæ¨¡å‹
  --deploy             å¯¼å‡ºåéƒ¨ç½²æ¨¡å‹
  --deploy-only        ä»…éƒ¨ç½²ï¼Œè·³è¿‡è®­ç»ƒ
  --skip-eval          è·³è¿‡è¯„ä¼°é˜¶æ®µ
  --checkpoint-dir     æ£€æŸ¥ç‚¹ç›®å½•
  --verbose            è¯¦ç»†æ—¥å¿—è¾“å‡º
  --dry-run            ä»…éªŒè¯é…ç½®ï¼Œä¸æ‰§è¡Œè®­ç»ƒ
```

### å…¸å‹å·¥ä½œæµ

#### 1. é…ç½®éªŒè¯

```bash
# éªŒè¯é…ç½®æ–‡ä»¶æ­£ç¡®æ€§
python main.py config/my_config.yaml --dry-run
```

#### 2. è®­ç»ƒæ¨¡å‹

```bash
# æ ‡å‡†è®­ç»ƒ
python main.py config/my_config.yaml

# è®­ç»ƒ + å¯¼å‡º
python main.py config/my_config.yaml --export

# è®­ç»ƒ + å¯¼å‡º + éƒ¨ç½²
python main.py config/my_config.yaml --export --deploy
```

#### 3. ä»…éƒ¨ç½²å·²æœ‰æ¨¡å‹

```bash
python main.py config/my_config.yaml --deploy-only
```

#### 4. è°ƒè¯•æ¨¡å¼

```bash
python main.py config/my_config.yaml --verbose
```

---

## é…ç½®æ–‡ä»¶

### é…ç½®æ–‡ä»¶ç»“æ„

è¯¦ç»†çš„é…ç½®æ–‡ä»¶è¯´æ˜è¯·å‚è€ƒï¼š[é…ç½®æ–‡ä»¶ç»“æ„è¯´æ˜æ–‡æ¡£](docs/é…ç½®æ–‡ä»¶ç»“æ„è¯´æ˜æ–‡æ¡£.md)

```yaml
global:           # å…¨å±€é…ç½®ï¼ˆé¡¹ç›®åç§°ã€ç‰ˆæœ¬ã€éšæœºç§å­ï¼‰
training_mode:    # è®­ç»ƒæ¨¡å¼ï¼ˆsupervised/reinforcement/unsupervisedç­‰ï¼‰
models:           # æ¨¡å‹å®šä¹‰
data_manager:     # æ•°æ®ç®¡ç†
optimizers:       # ä¼˜åŒ–å™¨é…ç½®
losses:           # æŸå¤±å‡½æ•°é…ç½®
training_pipeline:# è®­ç»ƒæµç¨‹
evaluation:       # è¯„ä¼°é…ç½®ï¼ˆå¯é€‰ï¼‰
export:           # æ¨¡å‹å¯¼å‡ºé…ç½®ï¼ˆå¯é€‰ï¼‰
deployment:       # æ¨¡å‹éƒ¨ç½²é…ç½®ï¼ˆå¯é€‰ï¼‰
```

### é…ç½®æ¨¡æ¿ç”Ÿæˆ

```python
from common.common import generate_config_template

# ç”Ÿæˆç›‘ç£å­¦ä¹ æ¨¡æ¿
generate_config_template("supervised", "my_supervised_config.yaml")

# ç”Ÿæˆå¼ºåŒ–å­¦ä¹ æ¨¡æ¿
generate_config_template("reinforcement", "my_rl_config.yaml")
```

---

## æ”¯æŒçš„è®­ç»ƒæ¨¡å¼

### 1. ç›‘ç£å­¦ä¹  (Supervised Learning)

é€‚ç”¨äºå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€æ–‡æœ¬åˆ†ç±»ç­‰ä»»åŠ¡ã€‚

**ç¤ºä¾‹é…ç½®ï¼š** `config/supervised_config.yaml`

**ç‰¹ç‚¹ï¼š**
- Epoch + Batch è®­ç»ƒå¾ªç¯
- æ ‡ç­¾æ•°æ®
- äº¤å‰ç†µæŸå¤±

### 2. å¼ºåŒ–å­¦ä¹  (Reinforcement Learning)

é€‚ç”¨äºæ¸¸æˆ AIã€æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ç­‰ä»»åŠ¡ã€‚

**ç¤ºä¾‹é…ç½®ï¼š** `config/reinforcement_config.yaml`

**ç‰¹ç‚¹ï¼š**
- Episode + Step è®­ç»ƒå¾ªç¯
- å¥–åŠ±ä¿¡å·
- ç­–ç•¥æ¢¯åº¦/Q-Learning

### 3. æ— ç›‘ç£å­¦ä¹  (Unsupervised Learning)

é€‚ç”¨äºèšç±»ã€é™ç»´ã€å¼‚å¸¸æ£€æµ‹ç­‰ä»»åŠ¡ã€‚

**ç‰¹ç‚¹ï¼š**
- è¿­ä»£è®­ç»ƒ
- æ— æ ‡ç­¾æ•°æ®
- é‡æ„æŸå¤±/èšç±»æŸå¤±

### 4. è‡ªç›‘ç£å­¦ä¹  (Self-Supervised Learning)

é€‚ç”¨äºå¯¹æ¯”å­¦ä¹ ã€æ©ç é¢„æµ‹ã€å›¾åƒä¿®å¤ç­‰ä»»åŠ¡ã€‚

**ç¤ºä¾‹é…ç½®ï¼š** `config/self_supervised_config.yaml`

**ç‰¹ç‚¹ï¼š**
- å¯¹æ¯”æŸå¤±
- æ•°æ®å¢å¼º
- é¢„è®­ç»ƒ-å¾®è°ƒ

### 5. åŠç›‘ç£å­¦ä¹  (Semi-Supervised Learning)

é€‚ç”¨äºå°‘é‡æ ‡æ³¨æ•°æ®çš„åœºæ™¯ã€‚

**ç‰¹ç‚¹ï¼š**
- æ ‡æ³¨ + æœªæ ‡æ³¨æ•°æ®
- ä¼ªæ ‡ç­¾
- ä¸€è‡´æ€§æ­£åˆ™åŒ–

### 6. å¤šä»»åŠ¡å­¦ä¹  (Multi-Task Learning)

åŒæ—¶è®­ç»ƒå¤šä¸ªç›¸å…³ä»»åŠ¡ã€‚

**ç‰¹ç‚¹ï¼š**
- å…±äº«ç¼–ç å™¨
- å¤šä¸ªä»»åŠ¡å¤´
- åŠ æƒæŸå¤±

### 7. è‡ªå®šä¹‰è®­ç»ƒ (Custom Training)

å®Œå…¨è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘ã€‚

**ç‰¹ç‚¹ï¼š**
- è‡ªç”±å®šä¹‰å¾ªç¯
- è‡ªå®šä¹‰æ­¥éª¤åºåˆ—
- Bridge æ§åˆ¶æµ

---

## æ¨¡å‹å¯¼å‡ºä¸éƒ¨ç½²

### æ”¯æŒçš„å¯¼å‡ºæ ¼å¼

| æ ¼å¼ | ç”¨é€” | æ–‡ä»¶æ‰©å±•å |
|------|------|-----------|
| **SavedModel** | TensorFlow Serving ç”Ÿäº§ç¯å¢ƒ | ç›®å½•ç»“æ„ |
| **ONNX** | è·¨å¹³å°éƒ¨ç½²ï¼ˆæ”¯æŒå¤šæ¡†æ¶ï¼‰ | `.onnx` |
| **TensorFlow Lite** | ç§»åŠ¨ç«¯å’ŒåµŒå…¥å¼è®¾å¤‡ | `.tflite` |
| **H5** | Keras æ ‡å‡†æ ¼å¼ | `.h5` |
| **Weights Only** | ä»…ä¿å­˜æƒé‡ | `.weights` |

### å¯¼å‡ºç¤ºä¾‹

```yaml
export:
  # SavedModel æ ¼å¼ï¼ˆTensorFlow Servingï¼‰
  export_savedmodel:
    model: "${classifier}"
    format: "savedmodel"
    output_path: "outputs/savedmodel/classifier"

  # ONNX æ ¼å¼ï¼ˆè·¨å¹³å°ï¼‰
  export_onnx:
    model: "${classifier}"
    format: "onnx"
    output_path: "outputs/onnx/classifier.onnx"
    args:
      opset_version: 13

  # TFLite æ ¼å¼ï¼ˆç§»åŠ¨ç«¯ï¼‰
  export_tflite:
    model: "${classifier}"
    format: "tflite"
    output_path: "outputs/tflite/classifier.tflite"
    args:
      optimizations: ["DEFAULT"]
```

### æ”¯æŒçš„éƒ¨ç½²æ–¹å¼

| éƒ¨ç½²æ–¹å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| **REST API** | Flask æœåŠ¡å™¨ | Web åº”ç”¨é›†æˆ |
| **gRPC** | é«˜æ€§èƒ½ RPC æœåŠ¡ | å¾®æœåŠ¡æ¶æ„ |
| **TensorFlow Serving** | å®˜æ–¹æ¨¡å‹æœåŠ¡ | ç”Ÿäº§ç¯å¢ƒ |
| **Docker** | å®¹å™¨åŒ–éƒ¨ç½² | äº‘å¹³å° |
| **è‡ªå®šä¹‰** | åå°„è°ƒç”¨è‡ªå®šä¹‰å‡½æ•° | ç‰¹æ®Šéœ€æ±‚ |

### éƒ¨ç½²ç¤ºä¾‹

```yaml
deployment:
  # REST API éƒ¨ç½²
  rest_api:
    type: "rest_api"
    model_path: "${export_paths.classifier}"
    host: "0.0.0.0"
    port: 9000
    endpoints:
      predict: "/api/predict"
      health: "/health"
    performance:
      batch_size: 32
      timeout: 30
      workers: 4
```

### å¿«é€Ÿå¯åŠ¨æœåŠ¡

```bash
# è®­ç»ƒå¹¶éƒ¨ç½²
python main.py config/my_config.yaml --export --deploy

# ä»…éƒ¨ç½²å·²æœ‰æ¨¡å‹
python main.py config/my_config.yaml --deploy-only
```

---

## é¡¹ç›®ç»“æ„

```
LearnAI/
â”œâ”€â”€ main.py                          # ä¸»å…¥å£
â”œâ”€â”€ requirements.txt                 # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                        # æœ¬æ–‡ä»¶
â”‚
â”œâ”€â”€ config/                          # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ config_example.yaml         # ç¤ºä¾‹é…ç½®
â”‚   â”œâ”€â”€ supervised_config.yaml      # ç›‘ç£å­¦ä¹ é…ç½®
â”‚   â”œâ”€â”€ reinforcement_config.yaml   # å¼ºåŒ–å­¦ä¹ é…ç½®
â”‚   â””â”€â”€ self_supervised_config.yaml # è‡ªç›‘ç£å­¦ä¹ é…ç½®
â”‚
â”œâ”€â”€ common/                          # å…¬å…±æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ common.py                   # åŸºç¡€åŠŸèƒ½ï¼ˆæ—¥å¿—ã€åå°„ã€é…ç½®ï¼‰
â”‚   â”œâ”€â”€ utils.py                    # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ train_context.py            # è®­ç»ƒä¸Šä¸‹æ–‡
â”‚   â”œâ”€â”€ interfaces.py               # æ¥å£å®šä¹‰
â”‚   â”œâ”€â”€ config_validator.py         # é…ç½®éªŒè¯
â”‚   â””â”€â”€ validators/                 # éªŒè¯å™¨å­æ¨¡å—
â”‚       â”œâ”€â”€ structure_validator.py
â”‚       â”œâ”€â”€ collection_validator.py
â”‚       â”œâ”€â”€ execution_validator.py
â”‚       â”œâ”€â”€ bridge_validator.py
â”‚       â”œâ”€â”€ connection_validator.py
â”‚       â””â”€â”€ cross_ref_validator.py
â”‚
â”œâ”€â”€ modules/                         # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_manager.py             # æ•°æ®ç®¡ç†
â”‚   â”œâ”€â”€ models.py                   # æ¨¡å‹æ„å»º
â”‚   â”œâ”€â”€ optimizers.py               # ä¼˜åŒ–å™¨ç®¡ç†
â”‚   â”œâ”€â”€ losses.py                   # æŸå¤±å‡½æ•°
â”‚   â”œâ”€â”€ training_pipeline.py        # è®­ç»ƒæµç¨‹
â”‚   â”œâ”€â”€ evaluation.py               # æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ export.py                   # æ¨¡å‹å¯¼å‡º
â”‚   â””â”€â”€ deployment.py               # æ¨¡å‹éƒ¨ç½²
â”‚
â”œâ”€â”€ lib/                             # ç¬¬ä¸‰æ–¹åº“å°è£…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ deployment.py               # éƒ¨ç½²å·¥å…·ï¼ˆFlask/gRPCï¼‰
â”‚
â”œâ”€â”€ data/                            # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ checkpoints/                     # æ£€æŸ¥ç‚¹ç›®å½•
â”œâ”€â”€ logs/                           # æ—¥å¿—ç›®å½•
â”œâ”€â”€ outputs/                        # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ onnx/
â”‚   â”œâ”€â”€ savedmodel/
â”‚   â”œâ”€â”€ tflite/
â”‚   â””â”€â”€ h5/
â”‚
â”œâ”€â”€ test/                           # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_modules.py
â”‚   â””â”€â”€ config_test.yaml
â”‚
â””â”€â”€ docs/                           # æ–‡æ¡£ç›®å½•
    â”œâ”€â”€ é…ç½®æ–‡ä»¶ç»“æ„è¯´æ˜æ–‡æ¡£.md
    â””â”€â”€ AIé©±åŠ¨çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ å¹³å°æ¼”è¿›è·¯çº¿å›¾.md
```

---

## å¼€å‘æŒ‡å—

### æ·»åŠ è‡ªå®šä¹‰ç»„ä»¶

#### 1. è‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨

åœ¨ `common/utils.py` æˆ– `modules/data_manager.py` ä¸­æ·»åŠ ï¼š

```python
def load_my_custom_data(file_path: str, batch_size: int = 32):
    """è‡ªå®šä¹‰æ•°æ®åŠ è½½å‡½æ•°"""
    # å®ç°æ•°æ®åŠ è½½é€»è¾‘
    dataset = ...
    return dataset
```

é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨ï¼š

```yaml
data_manager:
  custom_source:
    train:
      reflection: "common.utils:load_my_custom_data"
      args:
        file_path: "data/my_data.txt"
        batch_size: 32
```

#### 2. è‡ªå®šä¹‰æŸå¤±å‡½æ•°

åœ¨ `modules/losses.py` ä¸­æ·»åŠ ï¼š

```python
import tensorflow as tf

class MyCustomLoss(tf.keras.losses.Loss):
    """è‡ªå®šä¹‰æŸå¤±å‡½æ•°"""

    def __init__(self, alpha=1.0, **kwargs):
        super().__init__(**kwargs)
        self.alpha = alpha

    def call(self, y_true, y_pred):
        # å®ç°æŸå¤±è®¡ç®—é€»è¾‘
        loss = ...
        return loss
```

é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨ï¼š

```yaml
losses:
  custom_loss:
    reflection: "modules.losses:MyCustomLoss"
    args:
      alpha: 1.5
```

#### 3. è‡ªå®šä¹‰è®­ç»ƒæ­¥éª¤

åœ¨ `common/utils.py` ä¸­æ·»åŠ ï¼š

```python
def my_custom_training_step(model, optimizer, loss_fn, batch_data):
    """è‡ªå®šä¹‰è®­ç»ƒæ­¥éª¤"""
    inputs, labels = batch_data

    with tf.GradientTape() as tape:
        predictions = model(inputs, training=True)
        loss = loss_fn(labels, predictions)

    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    return loss
```

é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨ï¼š

```yaml
training_pipeline:
  custom:
    step_sequence:
      - name: "custom_step"
        reflection: "common.utils:my_custom_training_step"
        args:
          model: "${main_model}"
          optimizer: "${main_optimizer}"
          loss_fn: "${main_loss}"
          batch_data: "${current_batch}"
```

### ä»£ç è§„èŒƒ

æœ¬é¡¹ç›®éµå¾ª PEP 8 ä»£ç é£æ ¼æŒ‡å—ã€‚

```bash
# ä»£ç æ ¼å¼åŒ–
black .

# ä»£ç æ£€æŸ¥
flake8 .

# ç±»å‹æ£€æŸ¥
mypy .
```

### æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest test/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest test/test_modules.py::TestConfigLoading

# æŸ¥çœ‹æµ‹è¯•è¦†ç›–ç‡
pytest --cov=. --cov-report=html
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è°ƒè¯•é…ç½®æ–‡ä»¶ï¼Ÿ

**A:** ä½¿ç”¨ `--dry-run` é€‰é¡¹éªŒè¯é…ç½®ï¼š

```bash
python main.py config.yaml --dry-run
```

å¦‚æœé…ç½®æœ‰é”™è¯¯ï¼Œä¼šæ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œä¿®å¤å»ºè®®ã€‚

### Q2: å¦‚ä½•ä½¿ç”¨å¤š GPU è®­ç»ƒï¼Ÿ

**A:** åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®åˆ†å¸ƒå¼ç­–ç•¥ï¼š

```yaml
global:
  distributed_strategy:
    type: "MirroredStrategy"
    devices: ["GPU:0", "GPU:1"]
```

### Q3: å¦‚ä½•å®ç°æ¨¡å‹çƒ­æ›´æ–°ï¼Ÿ

**A:** åœ¨éƒ¨ç½²é…ç½®ä¸­å¯ç”¨è‡ªåŠ¨é‡è½½ï¼š

```yaml
deployment:
  rest_api:
    auto_reload: true
    reload_interval: 60  # æ¯60ç§’æ£€æŸ¥ä¸€æ¬¡
```

### Q4: è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•ä¿å­˜æ£€æŸ¥ç‚¹ï¼Ÿ

**A:** åœ¨è®­ç»ƒæµç¨‹ä¸­æ·»åŠ ä¿å­˜æ­¥éª¤ï¼š

```yaml
training_pipeline:
  supervised:
    step_sequence:
      # ... è®­ç»ƒæ­¥éª¤

      - name: "save_checkpoint"
        reflection: "common.utils:save_checkpoint"
        args:
          model: "${main_model}"
          epoch: "${current_epoch}"
        bridge: "@skip:save_checkpoint?${epoch}%5!=0"  # æ¯5è½®ä¿å­˜
```

### Q5: å¦‚ä½•é›†æˆè‡ªå·±çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Ÿ

**A:** é€šè¿‡åå°„æœºåˆ¶è°ƒç”¨ä»»ä½• Python åº“ï¼š

```yaml
models:
  my_pytorch_model:
    reflection: "my_pytorch_module:MyModel"
    args:
      input_dim: 784
      output_dim: 10
```

åªéœ€ç¡®ä¿ç›¸åº”çš„ Python åŒ…å·²å®‰è£…ã€‚

### Q6: å¦‚ä½•å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†ï¼Ÿ

**A:** ä½¿ç”¨ç±»æƒé‡æˆ–é‡é‡‡æ ·ï¼š

```yaml
losses:
  weighted_loss:
    reflection: "tensorflow.keras.losses.CategoricalCrossentropy"
    args:
      from_logits: false

training_pipeline:
  supervised:
    parameters:
      class_weight: {0: 1.0, 1: 2.0, 2: 3.0}  # ä¸ºå°‘æ•°ç±»å¢åŠ æƒé‡
```

### Q7: å¦‚ä½•å®ç°æ—©åœï¼ˆEarly Stoppingï¼‰ï¼Ÿ

**A:** ä½¿ç”¨ Bridge æ¡ä»¶æ§åˆ¶ï¼š

```yaml
step_sequence:
  - name: "check_early_stop"
    reflection: "common.utils:check_convergence"
    args:
      metric: "${val_loss}"
      patience: 10
    bridge: "@jump:save_and_exit?${converged}==true"
```

---

## æ›´æ–°æ—¥å¿—

### v2.0.0 (2025-11-03)

#### æ–°å¢åŠŸèƒ½
- âœ¨ å®Œæ•´çš„é…ç½®éªŒè¯ç³»ç»Ÿï¼ˆå¤šå±‚éªŒè¯å™¨ï¼‰
- âœ¨ Bridge è¡¨è¾¾å¼æ”¯æŒï¼ˆæ¡ä»¶æ§åˆ¶ã€å¾ªç¯ã€åˆ†æ”¯ï¼‰
- âœ¨ æ¨¡å‹å¯¼å‡ºæ”¯æŒ 5 ç§æ ¼å¼ï¼ˆSavedModel/ONNX/TFLite/H5/Weightsï¼‰
- âœ¨ æ¨¡å‹éƒ¨ç½²æ”¯æŒ 5 ç§æ–¹å¼ï¼ˆREST API/gRPC/TF Serving/Docker/Customï¼‰
- âœ¨ ç»Ÿä¸€çš„è®­ç»ƒä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆTrainContextï¼‰
- âœ¨ å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼ˆ37 ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰

#### æ”¹è¿›
- ğŸ”§ é‡æ„æ¨¡å—æ¶æ„ï¼Œæ¸…æ™°çš„èŒè´£åˆ’åˆ†
- ğŸ”§ æ”¹è¿›æ—¥å¿—ç³»ç»Ÿï¼Œæ”¯æŒå½©è‰²è¾“å‡ºå’Œæ–‡ä»¶è®°å½•
- ğŸ”§ ä¼˜åŒ–åå°„æœºåˆ¶ï¼Œæ”¯æŒæ›´çµæ´»çš„å‚æ•°ä¼ é€’
- ğŸ”§ å¢å¼ºé”™è¯¯å¤„ç†å’Œå¼‚å¸¸ä¿¡æ¯

#### æ–‡æ¡£
- ğŸ“š æ–°å¢é…ç½®æ–‡ä»¶ç»“æ„è¯´æ˜æ–‡æ¡£
- ğŸ“š æ–°å¢ AI é©±åŠ¨å¹³å°æ¼”è¿›è·¯çº¿å›¾
- ğŸ“š å®Œå–„ README å’Œ API æ–‡æ¡£

### v1.0.0 (2025-10-15)

#### åˆå§‹ç‰ˆæœ¬
- ğŸ‰ åŸºç¡€é…ç½®é©±åŠ¨æ¶æ„
- ğŸ‰ æ”¯æŒç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€è‡ªç›‘ç£å­¦ä¹ 
- ğŸ‰ åå°„æœºåˆ¶å®ç°
- ğŸ‰ åŸºç¡€æ¨¡å‹å¯¼å‡ºåŠŸèƒ½

---

## è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼

### å¦‚ä½•è´¡çŒ®

1. **Fork é¡¹ç›®**

```bash
git clone https://github.com/your-username/LearnAI.git
```

2. **åˆ›å»ºç‰¹æ€§åˆ†æ”¯**

```bash
git checkout -b feature/your-feature-name
```

3. **æäº¤æ›´æ”¹**

```bash
git commit -m "Add: æ·»åŠ æŸæŸåŠŸèƒ½"
```

4. **æ¨é€åˆ°åˆ†æ”¯**

```bash
git push origin feature/your-feature-name
```

5. **åˆ›å»º Pull Request**

åœ¨ GitHub ä¸Šåˆ›å»º PRï¼Œæè¿°æ‚¨çš„æ›´æ”¹ã€‚

### æäº¤ä¿¡æ¯è§„èŒƒ

```
Add: æ–°å¢åŠŸèƒ½
Fix: ä¿®å¤ bug
Docs: æ–‡æ¡£æ›´æ–°
Style: ä»£ç æ ¼å¼åŒ–
Refactor: ä»£ç é‡æ„
Test: æµ‹è¯•ç›¸å…³
Chore: æ„å»ºæˆ–è¾…åŠ©å·¥å…·çš„å˜åŠ¨
```

### ä»£ç å®¡æŸ¥æ ‡å‡†

- âœ… éµå¾ª PEP 8 ä»£ç é£æ ¼
- âœ… æ·»åŠ å¿…è¦çš„æµ‹è¯•
- âœ… æ›´æ–°ç›¸å…³æ–‡æ¡£
- âœ… ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
- âœ… æ·»åŠ æ¸…æ™°çš„æ³¨é‡Š

---

## è·¯çº¿å›¾

### è¿‘æœŸè®¡åˆ’ï¼ˆ3-6 ä¸ªæœˆï¼‰

- [ ] å¾®æœåŠ¡æ¶æ„æ”¹é€ 
- [ ] æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼ˆHorovod/Rayï¼‰
- [ ] Web UI æ§åˆ¶å°
- [ ] å®éªŒè¿½è¸ªç³»ç»Ÿï¼ˆMLflow é›†æˆï¼‰
- [ ] å®¹å™¨åŒ–éƒ¨ç½²ï¼ˆDocker + Kubernetesï¼‰

### ä¸­æœŸè®¡åˆ’ï¼ˆ6-12 ä¸ªæœˆï¼‰

- [ ] AutoML åŠŸèƒ½ï¼ˆNAS + è¶…å‚æ•°ä¼˜åŒ–ï¼‰
- [ ] æ™ºèƒ½æ•°æ®ç”Ÿæˆï¼ˆGAN/Diffusionï¼‰
- [ ] æ¨¡å‹å‹ç¼©å’Œé‡åŒ–
- [ ] æ€§èƒ½é¢„æµ‹å™¨
- [ ] A/B æµ‹è¯•æ”¯æŒ

### é•¿æœŸæ„¿æ™¯ï¼ˆ12-24 ä¸ªæœˆï¼‰

- [ ] LLM é©±åŠ¨çš„é…ç½®ç”Ÿæˆ
- [ ] å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨è°ƒä¼˜
- [ ] è‡ªä¸»ä»»åŠ¡å‘ç°
- [ ] å®Œå…¨è‡ªæ²»çš„è®­ç»ƒç³»ç»Ÿ

è¯¦è§ï¼š[AIé©±åŠ¨çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ å¹³å°æ¼”è¿›è·¯çº¿å›¾](docs/AIé©±åŠ¨çš„è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ å¹³å°æ¼”è¿›è·¯çº¿å›¾.md)

---

## ç¤¾åŒºä¸æ”¯æŒ

### è·å–å¸®åŠ©

- ğŸ“– [æ–‡æ¡£](docs/)
- ğŸ’¬ [GitHub Discussions](https://github.com/qqddtt/LearnAI/discussions)
- ğŸ› [é—®é¢˜åé¦ˆ](https://github.com/qqddtt/LearnAI/issues)
- ğŸ“§ Email: support@learnai.org

### å‚ä¸ç¤¾åŒº

- â­ ç»™é¡¹ç›®ç‚¹ Star
- ğŸ› æŠ¥å‘Š Bug
- ğŸ’¡ æå‡ºæ–°åŠŸèƒ½å»ºè®®
- ğŸ“ æ”¹è¿›æ–‡æ¡£
- ğŸ¤ æäº¤ Pull Request

---

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ **MIT è®¸å¯è¯**ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

```
MIT License

Copyright (c) 2025 LearnAI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®å’Œè´¡çŒ®è€…ï¼š

- [TensorFlow](https://www.tensorflow.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶
- [Keras](https://keras.io/) - é«˜å±‚ API
- [ONNX](https://onnx.ai/) - æ¨¡å‹äº¤æ¢æ ¼å¼
- [Flask](https://flask.palletsprojects.com/) - Web æ¡†æ¶
- [Ray](https://www.ray.io/) - åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
- [MLflow](https://mlflow.org/) - å®éªŒè¿½è¸ªç³»ç»Ÿ

æ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼

---

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº† LearnAIï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{learnai2025,
  title = {LearnAI: A Configuration-Driven Deep Learning Training Framework},
  author = {LearnAI Team},
  year = {2025},
  url = {https://github.com/qqddtt/LearnAI}
}
```

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Starï¼ â­**

Made with â¤ï¸ by [LearnAI Team](https://github.com/qqddtt)

[è¿”å›é¡¶éƒ¨](#learnai-æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶)

</div>
